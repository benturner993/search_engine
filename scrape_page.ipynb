{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2862f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c80b2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read urls to scrape\n",
    "urls=pd.read_csv('url/urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0eaad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set page information\n",
    "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "headers={'User-Agent':user_agent,} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8966ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507    https://www.bupa.co.uk/help-and-support/making...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[urls['url'].str.contains('claim')]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a5fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74ae908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4567887 https://www.bupa.co.uk/help-and-support/making-a-claim\n"
     ]
    }
   ],
   "source": [
    "for idx, url in enumerate(urls[urls['url'].str.contains('claim')]['url'][0:]):\n",
    "    \n",
    "    idx=idx+4567887\n",
    "    \n",
    "    # determine page index and url\n",
    "    print(idx, url)\n",
    "    \n",
    "    # scrape page\n",
    "    request=urllib.request.Request(url,None,headers) #The assembled request\n",
    "    response = urllib.request.urlopen(request)\n",
    "    data = response.read() # The data u need\n",
    "\n",
    "    # read page data with beautiful soup\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    \n",
    "    # create empty lists of information to create\n",
    "    titles=[]\n",
    "    main_headers=[]\n",
    "    bodies=[]\n",
    "\n",
    "    # read page title and save\n",
    "    for span in soup.find_all('title'):\n",
    "          titles.append(span.text)\n",
    "    \n",
    "    # read main header and save\n",
    "    for span in soup.find_all('h1'):\n",
    "          main_headers.append(span.text)\n",
    "    \n",
    "    # read whole body of text as tag\n",
    "    tag = soup.body\n",
    "    for string in tag.strings:\n",
    "        bodies.append(string)\n",
    "\n",
    "    # alter collected information to useable format\n",
    "    titles_cleaned=''.join(titles)\n",
    "    main_headers_cleaned=''.join(main_headers)    \n",
    "    bodies_cleaned = ''.join(bodies)\n",
    "    bodies_cleaned = bodies_cleaned.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"  \", \" \").strip()   \n",
    "    \n",
    "    # create a dataframe to store outputs\n",
    "    df=pd.DataFrame()\n",
    "    df['url']=[url]\n",
    "    df['title']=[titles_cleaned]\n",
    "    df['header']=[main_headers_cleaned]\n",
    "    df['body']=[bodies_cleaned]\n",
    "    \n",
    "    # export to csv using index as name\n",
    "    df.to_csv(f'pages/url_{str(idx)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f33ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
